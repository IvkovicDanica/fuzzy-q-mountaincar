{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import train\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca45451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 10 reward 10.0 MA(100) 37.70 eps 0.990\n",
      "Ep 20 reward -1.0 MA(100) 35.85 eps 0.980\n",
      "Ep 30 reward -11.0 MA(100) 21.30 eps 0.970\n",
      "Ep 40 reward -6.0 MA(100) 14.18 eps 0.961\n",
      "Ep 50 reward -3.0 MA(100) 10.56 eps 0.951\n",
      "Ep 60 reward -2.0 MA(100) 8.22 eps 0.942\n",
      "Ep 70 reward -2.0 MA(100) 6.11 eps 0.932\n",
      "Ep 80 reward -8.0 MA(100) 4.80 eps 0.923\n",
      "Ep 90 reward -7.0 MA(100) 3.22 eps 0.914\n",
      "Ep 100 reward -3.0 MA(100) 1.97 eps 0.905\n",
      "q_table stats: min -2.704, mean 0.023, max 1.560\n",
      "Ep 110 reward -4.0 MA(100) -2.12 eps 0.896\n",
      "Ep 120 reward 79.0 MA(100) -3.07 eps 0.887\n",
      "Ep 130 reward 101.0 MA(100) 7.23 eps 0.878\n",
      "Ep 140 reward 105.0 MA(100) 18.34 eps 0.869\n",
      "Ep 150 reward 87.0 MA(100) 28.69 eps 0.861\n",
      "Ep 160 reward 99.0 MA(100) 38.64 eps 0.852\n",
      "Ep 170 reward 86.0 MA(100) 48.51 eps 0.844\n",
      "Ep 180 reward 95.0 MA(100) 58.07 eps 0.835\n",
      "Ep 190 reward 86.0 MA(100) 67.97 eps 0.827\n",
      "Ep 200 reward 86.0 MA(100) 77.28 eps 0.819\n",
      "q_table stats: min -1.550, mean 2.414, max 9.808\n",
      "Ep 210 reward 91.0 MA(100) 86.52 eps 0.810\n",
      "Ep 220 reward 97.0 MA(100) 93.23 eps 0.802\n",
      "Ep 230 reward 95.0 MA(100) 93.05 eps 0.794\n",
      "Ep 240 reward 99.0 MA(100) 92.12 eps 0.787\n",
      "Ep 250 reward 122.0 MA(100) 92.75 eps 0.779\n",
      "Ep 260 reward 144.0 MA(100) 95.20 eps 0.771\n",
      "Ep 270 reward 98.0 MA(100) 97.08 eps 0.763\n",
      "Ep 280 reward 93.0 MA(100) 98.13 eps 0.756\n",
      "Ep 290 reward 101.0 MA(100) 99.91 eps 0.748\n",
      "Ep 300 reward 92.0 MA(100) 101.79 eps 0.741\n",
      "q_table stats: min -0.160, mean 5.875, max 22.192\n",
      "Ep 310 reward 103.0 MA(100) 102.66 eps 0.733\n",
      "Ep 320 reward 93.0 MA(100) 103.36 eps 0.726\n",
      "Ep 330 reward 96.0 MA(100) 103.76 eps 0.719\n",
      "Ep 340 reward 148.0 MA(100) 105.02 eps 0.712\n",
      "Ep 350 reward 180.0 MA(100) 109.58 eps 0.705\n",
      "Ep 360 reward 125.0 MA(100) 112.81 eps 0.698\n",
      "Ep 370 reward 149.0 MA(100) 116.17 eps 0.691\n",
      "Ep 380 reward 106.0 MA(100) 118.71 eps 0.684\n",
      "Ep 390 reward 104.0 MA(100) 119.35 eps 0.677\n",
      "Ep 400 reward 97.0 MA(100) 119.51 eps 0.670\n",
      "q_table stats: min -0.160, mean 9.734, max 37.725\n",
      "Ep 410 reward 150.0 MA(100) 125.15 eps 0.664\n",
      "Ep 420 reward 115.0 MA(100) 126.44 eps 0.657\n",
      "Ep 430 reward 110.0 MA(100) 127.63 eps 0.650\n",
      "Ep 440 reward 305.0 MA(100) 131.30 eps 0.644\n",
      "Ep 450 reward 111.0 MA(100) 127.88 eps 0.637\n",
      "Ep 460 reward 141.0 MA(100) 124.67 eps 0.631\n",
      "Ep 470 reward 94.0 MA(100) 121.36 eps 0.625\n",
      "Ep 480 reward 142.0 MA(100) 119.04 eps 0.619\n",
      "Ep 490 reward 95.0 MA(100) 119.31 eps 0.612\n",
      "Ep 500 reward 96.0 MA(100) 119.89 eps 0.606\n",
      "q_table stats: min -0.159, mean 13.362, max 50.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrija Lukic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygame\\pkgdata.py:27: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 510 reward 111.0 MA(100) 116.53 eps 0.600\n",
      "Ep 520 reward 132.0 MA(100) 117.14 eps 0.594\n",
      "Ep 530 reward 131.0 MA(100) 118.25 eps 0.588\n",
      "Ep 540 reward 94.0 MA(100) 114.44 eps 0.583\n",
      "Ep 550 reward 108.0 MA(100) 115.59 eps 0.577\n",
      "Ep 560 reward 152.0 MA(100) 117.12 eps 0.571\n",
      "Ep 570 reward 114.0 MA(100) 116.76 eps 0.565\n",
      "Ep 580 reward 95.0 MA(100) 117.28 eps 0.560\n",
      "Ep 590 reward 102.0 MA(100) 115.76 eps 0.554\n",
      "Ep 600 reward 100.0 MA(100) 116.64 eps 0.549\n",
      "q_table stats: min -0.158, mean 16.831, max 60.747\n",
      "Ep 610 reward 111.0 MA(100) 116.83 eps 0.543\n",
      "Ep 620 reward 123.0 MA(100) 117.29 eps 0.538\n",
      "Ep 630 reward 112.0 MA(100) 125.47 eps 0.532\n",
      "Ep 640 reward 107.0 MA(100) 128.56 eps 0.527\n",
      "Ep 650 reward 104.0 MA(100) 128.81 eps 0.522\n",
      "Ep 660 reward 120.0 MA(100) 128.92 eps 0.517\n",
      "Ep 670 reward 109.0 MA(100) 130.72 eps 0.512\n",
      "Ep 680 reward 113.0 MA(100) 131.93 eps 0.506\n",
      "Ep 690 reward 137.0 MA(100) 135.42 eps 0.501\n",
      "Ep 700 reward 128.0 MA(100) 136.01 eps 0.496\n",
      "q_table stats: min -0.150, mean 20.888, max 74.538\n",
      "Ep 710 reward 269.0 MA(100) 144.84 eps 0.491\n",
      "Ep 720 reward 127.0 MA(100) 151.59 eps 0.487\n",
      "Ep 730 reward 307.0 MA(100) 159.47 eps 0.482\n",
      "Ep 740 reward 122.0 MA(100) 164.14 eps 0.477\n",
      "Ep 750 reward 234.0 MA(100) 178.12 eps 0.472\n",
      "Ep 760 reward 178.0 MA(100) 183.86 eps 0.467\n",
      "Ep 770 reward 132.0 MA(100) 187.82 eps 0.463\n",
      "Ep 780 reward 109.0 MA(100) 188.20 eps 0.458\n",
      "Ep 790 reward 110.0 MA(100) 188.95 eps 0.454\n",
      "Ep 800 reward 100.0 MA(100) 189.45 eps 0.449\n",
      "q_table stats: min 0.634, mean 24.659, max 84.843\n",
      "Ep 810 reward 117.0 MA(100) 186.02 eps 0.445\n",
      "Ep 820 reward 123.0 MA(100) 182.57 eps 0.440\n",
      "Ep 830 reward 121.0 MA(100) 169.53 eps 0.436\n",
      "Ep 840 reward 217.0 MA(100) 167.64 eps 0.432\n",
      "Ep 850 reward 165.0 MA(100) 155.84 eps 0.427\n",
      "Ep 860 reward 101.0 MA(100) 147.25 eps 0.423\n",
      "Ep 870 reward 154.0 MA(100) 144.44 eps 0.419\n",
      "Ep 880 reward 205.0 MA(100) 153.10 eps 0.415\n",
      "Ep 890 reward 121.0 MA(100) 152.51 eps 0.410\n",
      "Ep 900 reward 115.0 MA(100) 150.54 eps 0.406\n",
      "q_table stats: min 1.342, mean 27.818, max 93.827\n",
      "Ep 910 reward 133.0 MA(100) 148.56 eps 0.402\n",
      "Ep 920 reward 156.0 MA(100) 151.11 eps 0.398\n",
      "Ep 930 reward 116.0 MA(100) 150.72 eps 0.394\n",
      "Ep 940 reward 109.0 MA(100) 146.97 eps 0.390\n",
      "Ep 950 reward 145.0 MA(100) 147.02 eps 0.387\n",
      "Ep 960 reward 157.0 MA(100) 165.49 eps 0.383\n",
      "Ep 970 reward 120.0 MA(100) 164.60 eps 0.379\n",
      "Ep 980 reward 161.0 MA(100) 159.39 eps 0.375\n",
      "Ep 990 reward 172.0 MA(100) 164.75 eps 0.371\n",
      "Ep 1000 reward 185.0 MA(100) 175.02 eps 0.368\n",
      "q_table stats: min 1.803, mean 31.283, max 102.352\n",
      "Ep 1010 reward 139.0 MA(100) 177.65 eps 0.364\n",
      "Ep 1020 reward 202.0 MA(100) 181.57 eps 0.360\n",
      "Ep 1030 reward 233.0 MA(100) 184.38 eps 0.357\n",
      "Ep 1040 reward 154.0 MA(100) 190.43 eps 0.353\n",
      "Ep 1050 reward 150.0 MA(100) 195.34 eps 0.350\n",
      "Ep 1060 reward 136.0 MA(100) 181.54 eps 0.346\n",
      "Ep 1070 reward 239.0 MA(100) 185.51 eps 0.343\n",
      "Ep 1080 reward 234.0 MA(100) 187.58 eps 0.339\n",
      "Ep 1090 reward 143.0 MA(100) 182.89 eps 0.336\n",
      "Ep 1100 reward 121.0 MA(100) 182.48 eps 0.333\n",
      "q_table stats: min 1.873, mean 34.299, max 109.711\n",
      "Ep 1110 reward 138.0 MA(100) 181.33 eps 0.329\n",
      "Ep 1120 reward 204.0 MA(100) 177.77 eps 0.326\n",
      "Ep 1130 reward 185.0 MA(100) 183.21 eps 0.323\n",
      "Ep 1140 reward 161.0 MA(100) 184.34 eps 0.320\n",
      "Ep 1150 reward 135.0 MA(100) 187.43 eps 0.316\n",
      "Ep 1160 reward 257.0 MA(100) 189.48 eps 0.313\n",
      "Ep 1170 reward 169.0 MA(100) 190.16 eps 0.310\n",
      "Ep 1180 reward 195.0 MA(100) 193.12 eps 0.307\n",
      "Ep 1190 reward 225.0 MA(100) 198.48 eps 0.304\n",
      "Ep 1200 reward 161.0 MA(100) 196.73 eps 0.301\n",
      "q_table stats: min 2.294, mean 37.436, max 117.858\n",
      "Ep 1210 reward 182.0 MA(100) 199.20 eps 0.298\n",
      "Ep 1220 reward 269.0 MA(100) 203.50 eps 0.295\n",
      "Ep 1230 reward 122.0 MA(100) 201.67 eps 0.292\n",
      "Ep 1240 reward 232.0 MA(100) 204.68 eps 0.289\n",
      "Ep 1250 reward 338.0 MA(100) 203.63 eps 0.286\n",
      "Ep 1260 reward 167.0 MA(100) 205.32 eps 0.283\n",
      "Ep 1270 reward 146.0 MA(100) 208.26 eps 0.281\n",
      "Ep 1280 reward 120.0 MA(100) 205.75 eps 0.278\n",
      "Ep 1290 reward 228.0 MA(100) 207.79 eps 0.275\n",
      "Ep 1300 reward 248.0 MA(100) 207.37 eps 0.272\n",
      "q_table stats: min 2.806, mean 40.399, max 125.218\n",
      "Ep 1310 reward 113.0 MA(100) 203.24 eps 0.270\n",
      "Ep 1320 reward 173.0 MA(100) 195.23 eps 0.267\n",
      "Ep 1330 reward 378.0 MA(100) 197.17 eps 0.264\n",
      "Ep 1340 reward 127.0 MA(100) 191.03 eps 0.262\n",
      "Ep 1350 reward 210.0 MA(100) 186.78 eps 0.259\n",
      "Ep 1360 reward 159.0 MA(100) 181.52 eps 0.256\n",
      "Ep 1370 reward 131.0 MA(100) 176.39 eps 0.254\n",
      "Ep 1380 reward 169.0 MA(100) 175.80 eps 0.251\n",
      "Ep 1390 reward 253.0 MA(100) 174.86 eps 0.249\n",
      "Ep 1400 reward 119.0 MA(100) 172.41 eps 0.246\n",
      "q_table stats: min 3.059, mean 42.073, max 126.884\n",
      "Ep 1410 reward 157.0 MA(100) 176.88 eps 0.244\n",
      "Ep 1420 reward 147.0 MA(100) 178.70 eps 0.242\n",
      "Ep 1430 reward 227.0 MA(100) 171.16 eps 0.239\n",
      "Ep 1440 reward 150.0 MA(100) 173.89 eps 0.237\n",
      "Ep 1450 reward 151.0 MA(100) 177.19 eps 0.234\n",
      "Ep 1460 reward 161.0 MA(100) 183.33 eps 0.232\n",
      "Ep 1470 reward 158.0 MA(100) 187.09 eps 0.230\n",
      "Ep 1480 reward 271.0 MA(100) 187.59 eps 0.227\n",
      "Ep 1490 reward 232.0 MA(100) 186.36 eps 0.225\n",
      "Ep 1500 reward 136.0 MA(100) 187.38 eps 0.223\n",
      "q_table stats: min 3.183, mean 43.714, max 129.602\n",
      "Ep 1510 reward 127.0 MA(100) 185.37 eps 0.221\n",
      "Ep 1520 reward 243.0 MA(100) 189.20 eps 0.219\n",
      "Ep 1530 reward 216.0 MA(100) 195.86 eps 0.216\n",
      "Ep 1540 reward 161.0 MA(100) 194.45 eps 0.214\n",
      "Ep 1550 reward 237.0 MA(100) 193.42 eps 0.212\n",
      "Ep 1560 reward 232.0 MA(100) 192.23 eps 0.210\n",
      "Ep 1570 reward 176.0 MA(100) 191.94 eps 0.208\n",
      "Ep 1580 reward 205.0 MA(100) 192.91 eps 0.206\n",
      "Ep 1590 reward 189.0 MA(100) 192.84 eps 0.204\n",
      "Ep 1600 reward 228.0 MA(100) 192.59 eps 0.202\n",
      "q_table stats: min 3.218, mean 45.026, max 130.802\n",
      "Ep 1610 reward 171.0 MA(100) 194.33 eps 0.200\n",
      "Ep 1620 reward 201.0 MA(100) 194.48 eps 0.198\n",
      "Ep 1630 reward 304.0 MA(100) 191.62 eps 0.196\n",
      "Ep 1640 reward 312.0 MA(100) 192.56 eps 0.194\n",
      "Ep 1650 reward 217.0 MA(100) 194.72 eps 0.192\n",
      "Ep 1660 reward 136.0 MA(100) 196.67 eps 0.190\n",
      "Ep 1670 reward 129.0 MA(100) 194.90 eps 0.188\n",
      "Ep 1680 reward 154.0 MA(100) 196.01 eps 0.186\n",
      "Ep 1690 reward 131.0 MA(100) 195.88 eps 0.184\n",
      "Ep 1700 reward 272.0 MA(100) 203.06 eps 0.183\n",
      "q_table stats: min 3.253, mean 46.155, max 131.892\n",
      "Ep 1710 reward 172.0 MA(100) 201.80 eps 0.181\n",
      "Ep 1720 reward 191.0 MA(100) 201.11 eps 0.179\n",
      "Ep 1730 reward 238.0 MA(100) 202.89 eps 0.177\n",
      "Ep 1740 reward 151.0 MA(100) 199.19 eps 0.175\n",
      "Ep 1750 reward 117.0 MA(100) 196.82 eps 0.174\n",
      "Ep 1760 reward 272.0 MA(100) 197.34 eps 0.172\n",
      "Ep 1770 reward 274.0 MA(100) 199.90 eps 0.170\n",
      "Ep 1780 reward 155.0 MA(100) 199.23 eps 0.168\n",
      "Ep 1790 reward 184.0 MA(100) 198.52 eps 0.167\n",
      "Ep 1800 reward 224.0 MA(100) 196.20 eps 0.165\n",
      "q_table stats: min 3.288, mean 47.009, max 131.796\n",
      "Ep 1810 reward 116.0 MA(100) 194.34 eps 0.164\n",
      "Ep 1820 reward 122.0 MA(100) 194.80 eps 0.162\n",
      "Ep 1830 reward 222.0 MA(100) 191.34 eps 0.160\n",
      "Ep 1840 reward 223.0 MA(100) 193.86 eps 0.159\n",
      "Ep 1850 reward 234.0 MA(100) 191.38 eps 0.157\n",
      "Ep 1860 reward 202.0 MA(100) 190.34 eps 0.156\n",
      "Ep 1870 reward 195.0 MA(100) 187.65 eps 0.154\n",
      "Ep 1880 reward 202.0 MA(100) 189.42 eps 0.152\n",
      "Ep 1890 reward 196.0 MA(100) 187.73 eps 0.151\n",
      "Ep 1900 reward 157.0 MA(100) 182.30 eps 0.149\n",
      "q_table stats: min 3.291, mean 47.474, max 130.972\n",
      "Ep 1910 reward 134.0 MA(100) 187.18 eps 0.148\n",
      "Ep 1920 reward 186.0 MA(100) 182.61 eps 0.146\n",
      "Ep 1930 reward 133.0 MA(100) 183.52 eps 0.145\n",
      "Ep 1940 reward 127.0 MA(100) 187.78 eps 0.144\n",
      "Ep 1950 reward 124.0 MA(100) 185.86 eps 0.142\n",
      "Ep 1960 reward 203.0 MA(100) 184.77 eps 0.141\n",
      "Ep 1970 reward 220.0 MA(100) 187.13 eps 0.139\n",
      "Ep 1980 reward 223.0 MA(100) 184.48 eps 0.138\n",
      "Ep 1990 reward 201.0 MA(100) 185.58 eps 0.137\n",
      "Ep 2000 reward 145.0 MA(100) 187.11 eps 0.135\n",
      "q_table stats: min 3.279, mean 47.677, max 129.337\n",
      "Ep 2010 reward 259.0 MA(100) 186.03 eps 0.134\n",
      "Ep 2020 reward 265.0 MA(100) 190.14 eps 0.133\n",
      "Ep 2030 reward 211.0 MA(100) 196.03 eps 0.131\n",
      "Ep 2040 reward 336.0 MA(100) 194.63 eps 0.130\n",
      "Ep 2050 reward 198.0 MA(100) 196.11 eps 0.129\n",
      "Ep 2060 reward 171.0 MA(100) 197.91 eps 0.127\n",
      "Ep 2070 reward 134.0 MA(100) 196.33 eps 0.126\n",
      "Ep 2080 reward 153.0 MA(100) 197.64 eps 0.125\n",
      "Ep 2090 reward 210.0 MA(100) 197.44 eps 0.124\n",
      "Ep 2100 reward 142.0 MA(100) 196.82 eps 0.122\n",
      "q_table stats: min 3.271, mean 47.855, max 128.170\n",
      "Ep 2110 reward 190.0 MA(100) 197.30 eps 0.121\n",
      "Ep 2120 reward 235.0 MA(100) 197.09 eps 0.120\n",
      "Ep 2130 reward 251.0 MA(100) 191.02 eps 0.119\n",
      "Ep 2140 reward 227.0 MA(100) 189.15 eps 0.118\n",
      "Ep 2150 reward 208.0 MA(100) 192.54 eps 0.116\n",
      "Ep 2160 reward 233.0 MA(100) 192.49 eps 0.115\n",
      "Ep 2170 reward 302.0 MA(100) 198.85 eps 0.114\n",
      "Ep 2180 reward 184.0 MA(100) 196.43 eps 0.113\n",
      "Ep 2190 reward 145.0 MA(100) 197.35 eps 0.112\n",
      "Ep 2200 reward 174.0 MA(100) 197.13 eps 0.111\n",
      "q_table stats: min 3.247, mean 47.844, max 126.274\n",
      "Ep 2210 reward 211.0 MA(100) 197.66 eps 0.110\n",
      "Ep 2220 reward 236.0 MA(100) 195.01 eps 0.108\n",
      "Ep 2230 reward 201.0 MA(100) 194.79 eps 0.107\n",
      "Ep 2240 reward 217.0 MA(100) 193.45 eps 0.106\n",
      "Ep 2250 reward 226.0 MA(100) 193.96 eps 0.105\n",
      "Ep 2260 reward 195.0 MA(100) 191.74 eps 0.104\n",
      "Ep 2270 reward 195.0 MA(100) 186.51 eps 0.103\n",
      "Ep 2280 reward 210.0 MA(100) 187.03 eps 0.102\n",
      "Ep 2290 reward 143.0 MA(100) 184.25 eps 0.101\n",
      "Ep 2300 reward 153.0 MA(100) 183.57 eps 0.100\n",
      "q_table stats: min 3.225, mean 47.631, max 123.985\n",
      "Ep 2310 reward 208.0 MA(100) 181.13 eps 0.099\n",
      "Ep 2320 reward 145.0 MA(100) 181.16 eps 0.098\n",
      "Ep 2330 reward 130.0 MA(100) 180.49 eps 0.097\n",
      "Ep 2340 reward 195.0 MA(100) 181.21 eps 0.096\n",
      "Ep 2350 reward 188.0 MA(100) 176.78 eps 0.095\n",
      "Ep 2360 reward 132.0 MA(100) 174.70 eps 0.094\n",
      "Ep 2370 reward 192.0 MA(100) 173.34 eps 0.093\n",
      "Ep 2380 reward 221.0 MA(100) 173.05 eps 0.092\n",
      "Ep 2390 reward 183.0 MA(100) 176.07 eps 0.092\n",
      "Ep 2400 reward 254.0 MA(100) 179.42 eps 0.091\n",
      "q_table stats: min 3.208, mean 47.343, max 121.895\n",
      "Ep 2410 reward 230.0 MA(100) 177.78 eps 0.090\n",
      "Ep 2420 reward 241.0 MA(100) 178.78 eps 0.089\n",
      "Ep 2430 reward 194.0 MA(100) 180.45 eps 0.088\n",
      "Ep 2440 reward 223.0 MA(100) 180.78 eps 0.087\n",
      "Ep 2450 reward 185.0 MA(100) 182.32 eps 0.086\n",
      "Ep 2460 reward 153.0 MA(100) 182.40 eps 0.085\n",
      "Ep 2470 reward 137.0 MA(100) 181.46 eps 0.084\n",
      "Ep 2480 reward 215.0 MA(100) 182.17 eps 0.084\n",
      "Ep 2490 reward 157.0 MA(100) 181.24 eps 0.083\n",
      "Ep 2500 reward 267.0 MA(100) 180.37 eps 0.082\n",
      "q_table stats: min 3.180, mean 46.995, max 119.874\n",
      "Ep 2510 reward 160.0 MA(100) 181.49 eps 0.081\n",
      "Ep 2520 reward 127.0 MA(100) 180.78 eps 0.080\n",
      "Ep 2530 reward 130.0 MA(100) 179.56 eps 0.080\n",
      "Ep 2540 reward 178.0 MA(100) 179.64 eps 0.079\n",
      "Ep 2550 reward 227.0 MA(100) 180.61 eps 0.078\n",
      "Ep 2560 reward 197.0 MA(100) 182.89 eps 0.077\n",
      "Ep 2570 reward 246.0 MA(100) 183.38 eps 0.076\n",
      "Ep 2580 reward 127.0 MA(100) 180.44 eps 0.076\n",
      "Ep 2590 reward 189.0 MA(100) 181.55 eps 0.075\n",
      "Ep 2600 reward 213.0 MA(100) 179.56 eps 0.074\n",
      "q_table stats: min 3.144, mean 46.473, max 117.675\n",
      "Ep 2610 reward 175.0 MA(100) 179.36 eps 0.073\n",
      "Ep 2620 reward 148.0 MA(100) 178.42 eps 0.073\n",
      "Ep 2630 reward 138.0 MA(100) 177.10 eps 0.072\n",
      "Ep 2640 reward 214.0 MA(100) 176.78 eps 0.071\n",
      "Ep 2650 reward 168.0 MA(100) 174.27 eps 0.071\n",
      "Ep 2660 reward 245.0 MA(100) 175.78 eps 0.070\n",
      "Ep 2670 reward 217.0 MA(100) 177.20 eps 0.069\n",
      "Ep 2680 reward 206.0 MA(100) 178.65 eps 0.068\n",
      "Ep 2690 reward 121.0 MA(100) 175.04 eps 0.068\n",
      "Ep 2700 reward 185.0 MA(100) 175.24 eps 0.067\n",
      "q_table stats: min 3.110, mean 46.028, max 115.910\n",
      "Ep 2710 reward 251.0 MA(100) 175.02 eps 0.066\n",
      "Ep 2720 reward 148.0 MA(100) 174.62 eps 0.066\n",
      "Ep 2730 reward 260.0 MA(100) 176.74 eps 0.065\n",
      "Ep 2740 reward 158.0 MA(100) 174.71 eps 0.064\n",
      "Ep 2750 reward 115.0 MA(100) 175.37 eps 0.064\n",
      "Ep 2760 reward 177.0 MA(100) 172.77 eps 0.063\n",
      "Ep 2770 reward 222.0 MA(100) 170.69 eps 0.063\n",
      "Ep 2780 reward 131.0 MA(100) 168.58 eps 0.062\n",
      "Ep 2790 reward 121.0 MA(100) 170.50 eps 0.061\n",
      "Ep 2800 reward 225.0 MA(100) 169.32 eps 0.061\n",
      "q_table stats: min 3.087, mean 45.566, max 114.604\n",
      "Ep 2810 reward 230.0 MA(100) 170.52 eps 0.060\n",
      "Ep 2820 reward 213.0 MA(100) 170.88 eps 0.060\n",
      "Ep 2830 reward 135.0 MA(100) 170.29 eps 0.059\n",
      "Ep 2840 reward 242.0 MA(100) 173.15 eps 0.058\n",
      "Ep 2850 reward 114.0 MA(100) 173.22 eps 0.058\n",
      "Ep 2860 reward 194.0 MA(100) 175.37 eps 0.057\n",
      "Ep 2870 reward 125.0 MA(100) 176.23 eps 0.057\n",
      "Ep 2880 reward 205.0 MA(100) 179.09 eps 0.056\n",
      "Ep 2890 reward 207.0 MA(100) 178.77 eps 0.055\n",
      "Ep 2900 reward 133.0 MA(100) 179.54 eps 0.055\n",
      "q_table stats: min 3.068, mean 45.107, max 113.057\n",
      "Ep 2910 reward 193.0 MA(100) 182.07 eps 0.054\n",
      "Ep 2920 reward 135.0 MA(100) 182.82 eps 0.054\n",
      "Ep 2930 reward 210.0 MA(100) 182.56 eps 0.053\n",
      "Ep 2940 reward 180.0 MA(100) 181.38 eps 0.053\n",
      "Ep 2950 reward 196.0 MA(100) 182.89 eps 0.052\n",
      "Ep 2960 reward 228.0 MA(100) 182.29 eps 0.052\n",
      "Ep 2970 reward 124.0 MA(100) 183.05 eps 0.051\n",
      "Ep 2980 reward 178.0 MA(100) 184.51 eps 0.051\n",
      "Ep 2990 reward 136.0 MA(100) 184.66 eps 0.050\n",
      "Ep 3000 reward 120.0 MA(100) 187.30 eps 0.050\n",
      "q_table stats: min 3.047, mean 44.646, max 111.693\n",
      "Ep 3010 reward 178.0 MA(100) 184.17 eps 0.049\n",
      "Ep 3020 reward 151.0 MA(100) 183.92 eps 0.049\n",
      "Ep 3030 reward 224.0 MA(100) 184.32 eps 0.048\n",
      "Ep 3040 reward 236.0 MA(100) 184.22 eps 0.048\n",
      "Ep 3050 reward 194.0 MA(100) 183.25 eps 0.047\n",
      "Ep 3060 reward 206.0 MA(100) 181.98 eps 0.047\n",
      "Ep 3070 reward 212.0 MA(100) 182.65 eps 0.046\n",
      "Ep 3080 reward 214.0 MA(100) 181.96 eps 0.046\n",
      "Ep 3090 reward 117.0 MA(100) 180.83 eps 0.045\n",
      "Ep 3100 reward 136.0 MA(100) 181.07 eps 0.045\n",
      "q_table stats: min 3.026, mean 44.142, max 110.224\n",
      "Ep 3110 reward 210.0 MA(100) 182.61 eps 0.045\n",
      "Ep 3120 reward 148.0 MA(100) 183.22 eps 0.044\n",
      "Ep 3130 reward 212.0 MA(100) 183.62 eps 0.044\n",
      "Ep 3140 reward 133.0 MA(100) 182.74 eps 0.043\n",
      "Ep 3150 reward 135.0 MA(100) 183.07 eps 0.043\n",
      "Ep 3160 reward 158.0 MA(100) 183.49 eps 0.042\n",
      "Ep 3170 reward 234.0 MA(100) 182.56 eps 0.042\n",
      "Ep 3180 reward 226.0 MA(100) 181.81 eps 0.042\n",
      "Ep 3190 reward 133.0 MA(100) 182.60 eps 0.041\n",
      "Ep 3200 reward 221.0 MA(100) 181.79 eps 0.041\n",
      "q_table stats: min 3.015, mean 43.771, max 108.799\n",
      "Ep 3210 reward 128.0 MA(100) 178.97 eps 0.040\n",
      "Ep 3220 reward 135.0 MA(100) 178.81 eps 0.040\n",
      "Ep 3230 reward 236.0 MA(100) 178.85 eps 0.039\n",
      "Ep 3240 reward 183.0 MA(100) 177.99 eps 0.039\n",
      "Ep 3250 reward 200.0 MA(100) 177.24 eps 0.039\n",
      "Ep 3260 reward 210.0 MA(100) 177.36 eps 0.038\n",
      "Ep 3270 reward 201.0 MA(100) 176.96 eps 0.038\n",
      "Ep 3280 reward 176.0 MA(100) 176.57 eps 0.038\n",
      "Ep 3290 reward 140.0 MA(100) 178.59 eps 0.037\n",
      "Ep 3300 reward 126.0 MA(100) 175.96 eps 0.037\n",
      "q_table stats: min 2.999, mean 43.409, max 107.213\n",
      "Ep 3310 reward 136.0 MA(100) 176.54 eps 0.036\n",
      "Ep 3320 reward 112.0 MA(100) 177.20 eps 0.036\n",
      "Ep 3330 reward 149.0 MA(100) 176.03 eps 0.036\n",
      "Ep 3340 reward 177.0 MA(100) 177.59 eps 0.035\n",
      "Ep 3350 reward 193.0 MA(100) 176.58 eps 0.035\n",
      "Ep 3360 reward 175.0 MA(100) 173.98 eps 0.035\n",
      "Ep 3370 reward 136.0 MA(100) 172.40 eps 0.034\n",
      "Ep 3380 reward 191.0 MA(100) 172.91 eps 0.034\n",
      "Ep 3390 reward 241.0 MA(100) 170.66 eps 0.034\n",
      "Ep 3400 reward 168.0 MA(100) 170.40 eps 0.033\n",
      "q_table stats: min 2.799, mean 43.101, max 106.680\n",
      "Ep 3410 reward 195.0 MA(100) 169.99 eps 0.033\n",
      "Ep 3420 reward 132.0 MA(100) 169.01 eps 0.033\n",
      "Ep 3430 reward 147.0 MA(100) 168.65 eps 0.032\n",
      "Ep 3440 reward 216.0 MA(100) 169.24 eps 0.032\n",
      "Ep 3450 reward 134.0 MA(100) 170.62 eps 0.032\n",
      "Ep 3460 reward 199.0 MA(100) 172.18 eps 0.031\n",
      "Ep 3470 reward 226.0 MA(100) 174.61 eps 0.031\n",
      "Ep 3480 reward 195.0 MA(100) 173.59 eps 0.031\n",
      "Ep 3490 reward 226.0 MA(100) 171.86 eps 0.030\n",
      "Ep 3500 reward 198.0 MA(100) 173.56 eps 0.030\n",
      "q_table stats: min 2.370, mean 42.765, max 106.068\n",
      "Ep 3510 reward 122.0 MA(100) 174.59 eps 0.030\n",
      "Ep 3520 reward 210.0 MA(100) 176.76 eps 0.030\n",
      "Ep 3530 reward 249.0 MA(100) 178.98 eps 0.029\n",
      "Ep 3540 reward 137.0 MA(100) 179.97 eps 0.029\n",
      "Ep 3550 reward 178.0 MA(100) 181.40 eps 0.029\n",
      "Ep 3560 reward 237.0 MA(100) 180.10 eps 0.028\n",
      "Ep 3570 reward 129.0 MA(100) 179.30 eps 0.028\n",
      "Ep 3580 reward 242.0 MA(100) 180.18 eps 0.028\n",
      "Ep 3590 reward 207.0 MA(100) 185.11 eps 0.028\n",
      "Ep 3600 reward 187.0 MA(100) 183.92 eps 0.027\n",
      "q_table stats: min 2.027, mean 42.468, max 104.518\n",
      "Ep 3610 reward 200.0 MA(100) 182.27 eps 0.027\n",
      "Ep 3620 reward 196.0 MA(100) 182.11 eps 0.027\n",
      "Ep 3630 reward 211.0 MA(100) 181.00 eps 0.026\n",
      "Ep 3640 reward 132.0 MA(100) 179.29 eps 0.026\n",
      "Ep 3650 reward 182.0 MA(100) 177.70 eps 0.026\n",
      "Ep 3660 reward 133.0 MA(100) 176.93 eps 0.026\n",
      "Ep 3670 reward 167.0 MA(100) 179.36 eps 0.025\n",
      "Ep 3680 reward 168.0 MA(100) 179.28 eps 0.025\n",
      "Ep 3690 reward 147.0 MA(100) 176.21 eps 0.025\n",
      "Ep 3700 reward 124.0 MA(100) 177.14 eps 0.025\n",
      "q_table stats: min 1.708, mean 42.231, max 103.388\n",
      "Ep 3710 reward 147.0 MA(100) 178.76 eps 0.024\n",
      "Ep 3720 reward 217.0 MA(100) 175.69 eps 0.024\n",
      "Ep 3730 reward 203.0 MA(100) 174.71 eps 0.024\n",
      "Ep 3740 reward 172.0 MA(100) 173.67 eps 0.024\n",
      "Ep 3750 reward 228.0 MA(100) 173.95 eps 0.023\n",
      "Ep 3760 reward 146.0 MA(100) 177.54 eps 0.023\n",
      "Ep 3770 reward 261.0 MA(100) 178.20 eps 0.023\n",
      "Ep 3780 reward 236.0 MA(100) 181.08 eps 0.023\n",
      "Ep 3790 reward 161.0 MA(100) 182.06 eps 0.023\n",
      "Ep 3800 reward 192.0 MA(100) 183.65 eps 0.022\n",
      "q_table stats: min 1.402, mean 42.024, max 102.573\n",
      "Ep 3810 reward 122.0 MA(100) 184.50 eps 0.022\n",
      "Ep 3820 reward 153.0 MA(100) 187.04 eps 0.022\n",
      "Ep 3830 reward 223.0 MA(100) 188.97 eps 0.022\n",
      "Ep 3840 reward 185.0 MA(100) 192.35 eps 0.021\n",
      "Ep 3850 reward 157.0 MA(100) 191.84 eps 0.021\n",
      "Ep 3860 reward 129.0 MA(100) 193.76 eps 0.021\n",
      "Ep 3870 reward 124.0 MA(100) 192.07 eps 0.021\n",
      "Ep 3880 reward 218.0 MA(100) 188.13 eps 0.021\n",
      "Ep 3890 reward 211.0 MA(100) 186.33 eps 0.020\n",
      "Ep 3900 reward 195.0 MA(100) 185.39 eps 0.020\n",
      "q_table stats: min 1.107, mean 41.872, max 101.714\n",
      "Ep 3910 reward 205.0 MA(100) 187.94 eps 0.020\n",
      "Ep 3920 reward 239.0 MA(100) 188.90 eps 0.020\n",
      "Ep 3930 reward 183.0 MA(100) 187.62 eps 0.020\n",
      "Ep 3940 reward 131.0 MA(100) 189.49 eps 0.019\n",
      "Ep 3950 reward 214.0 MA(100) 190.06 eps 0.019\n",
      "Ep 3960 reward 141.0 MA(100) 186.82 eps 0.019\n",
      "Ep 3970 reward 133.0 MA(100) 185.63 eps 0.019\n",
      "Ep 3980 reward 217.0 MA(100) 186.25 eps 0.019\n",
      "Ep 3990 reward 178.0 MA(100) 186.77 eps 0.018\n",
      "Ep 4000 reward 185.0 MA(100) 186.77 eps 0.018\n",
      "q_table stats: min 0.736, mean 41.648, max 101.079\n",
      "Ep 4010 reward 226.0 MA(100) 183.81 eps 0.018\n",
      "Ep 4020 reward 218.0 MA(100) 181.95 eps 0.018\n",
      "Ep 4030 reward 167.0 MA(100) 183.11 eps 0.018\n",
      "Ep 4040 reward 212.0 MA(100) 179.36 eps 0.018\n",
      "Ep 4050 reward 133.0 MA(100) 179.49 eps 0.017\n",
      "Ep 4060 reward 196.0 MA(100) 179.48 eps 0.017\n",
      "Ep 4070 reward 197.0 MA(100) 180.45 eps 0.017\n",
      "Ep 4080 reward 123.0 MA(100) 180.23 eps 0.017\n",
      "Ep 4090 reward 173.0 MA(100) 180.92 eps 0.017\n",
      "Ep 4100 reward 115.0 MA(100) 181.81 eps 0.017\n",
      "q_table stats: min 0.449, mean 41.491, max 100.547\n",
      "Ep 4110 reward 163.0 MA(100) 179.84 eps 0.016\n",
      "Ep 4120 reward 147.0 MA(100) 180.87 eps 0.016\n",
      "Ep 4130 reward 140.0 MA(100) 179.77 eps 0.016\n",
      "Ep 4140 reward 244.0 MA(100) 182.59 eps 0.016\n",
      "Ep 4150 reward 127.0 MA(100) 184.21 eps 0.016\n",
      "Ep 4160 reward 135.0 MA(100) 182.93 eps 0.016\n",
      "Ep 4170 reward 145.0 MA(100) 183.00 eps 0.015\n",
      "Ep 4180 reward 247.0 MA(100) 183.16 eps 0.015\n",
      "Ep 4190 reward 226.0 MA(100) 185.68 eps 0.015\n",
      "Ep 4200 reward 199.0 MA(100) 183.99 eps 0.015\n",
      "q_table stats: min 0.119, mean 41.340, max 100.161\n",
      "Ep 4210 reward 267.0 MA(100) 185.71 eps 0.015\n",
      "Ep 4220 reward 250.0 MA(100) 186.74 eps 0.015\n",
      "Ep 4230 reward 214.0 MA(100) 188.83 eps 0.015\n",
      "Ep 4240 reward 234.0 MA(100) 186.02 eps 0.014\n",
      "Ep 4250 reward 248.0 MA(100) 184.98 eps 0.014\n",
      "Ep 4260 reward 200.0 MA(100) 189.22 eps 0.014\n",
      "Ep 4270 reward 129.0 MA(100) 189.82 eps 0.014\n",
      "Ep 4280 reward 176.0 MA(100) 190.34 eps 0.014\n",
      "Ep 4290 reward 169.0 MA(100) 188.64 eps 0.014\n",
      "Ep 4300 reward 206.0 MA(100) 191.26 eps 0.014\n",
      "q_table stats: min -0.196, mean 41.215, max 99.986\n",
      "Ep 4310 reward 125.0 MA(100) 192.09 eps 0.013\n",
      "Ep 4320 reward 183.0 MA(100) 192.07 eps 0.013\n",
      "Ep 4330 reward 244.0 MA(100) 188.46 eps 0.013\n",
      "Ep 4340 reward 194.0 MA(100) 189.31 eps 0.013\n",
      "Ep 4350 reward 120.0 MA(100) 189.00 eps 0.013\n",
      "Ep 4360 reward 120.0 MA(100) 186.54 eps 0.013\n",
      "Ep 4370 reward 140.0 MA(100) 187.74 eps 0.013\n",
      "Ep 4380 reward 174.0 MA(100) 192.99 eps 0.012\n",
      "Ep 4390 reward 312.0 MA(100) 197.25 eps 0.012\n",
      "Ep 4400 reward 198.0 MA(100) 196.09 eps 0.012\n",
      "q_table stats: min -0.537, mean 41.094, max 99.812\n",
      "Ep 4410 reward 194.0 MA(100) 194.89 eps 0.012\n",
      "Ep 4420 reward 222.0 MA(100) 198.34 eps 0.012\n",
      "Ep 4430 reward 125.0 MA(100) 201.94 eps 0.012\n",
      "Ep 4440 reward 351.0 MA(100) 204.14 eps 0.012\n",
      "Ep 4450 reward 203.0 MA(100) 205.40 eps 0.012\n",
      "Ep 4460 reward 285.0 MA(100) 208.71 eps 0.012\n",
      "Ep 4470 reward 233.0 MA(100) 207.47 eps 0.011\n",
      "Ep 4480 reward 151.0 MA(100) 201.83 eps 0.011\n",
      "Ep 4490 reward 244.0 MA(100) 200.40 eps 0.011\n",
      "Ep 4500 reward 131.0 MA(100) 201.13 eps 0.011\n",
      "q_table stats: min -0.859, mean 41.006, max 99.750\n",
      "Ep 4510 reward 150.0 MA(100) 203.27 eps 0.011\n",
      "Ep 4520 reward 154.0 MA(100) 198.55 eps 0.011\n",
      "Ep 4530 reward 136.0 MA(100) 198.17 eps 0.011\n",
      "Ep 4540 reward 135.0 MA(100) 196.24 eps 0.011\n",
      "Ep 4550 reward 163.0 MA(100) 196.13 eps 0.011\n",
      "Ep 4560 reward 147.0 MA(100) 193.05 eps 0.010\n",
      "Ep 4570 reward 328.0 MA(100) 192.59 eps 0.010\n",
      "Ep 4580 reward 196.0 MA(100) 193.39 eps 0.010\n",
      "Ep 4590 reward 191.0 MA(100) 192.64 eps 0.010\n",
      "Ep 4600 reward 157.0 MA(100) 194.24 eps 0.010\n",
      "q_table stats: min -1.052, mean 40.992, max 99.752\n",
      "Ep 4610 reward 271.0 MA(100) 197.58 eps 0.010\n",
      "Ep 4620 reward 250.0 MA(100) 201.10 eps 0.010\n",
      "Ep 4630 reward 125.0 MA(100) 200.49 eps 0.010\n",
      "Ep 4640 reward 195.0 MA(100) 203.07 eps 0.010\n",
      "Ep 4650 reward 188.0 MA(100) 200.13 eps 0.010\n",
      "Ep 4660 reward 200.0 MA(100) 204.17 eps 0.010\n",
      "Ep 4670 reward 159.0 MA(100) 203.69 eps 0.010\n",
      "Ep 4680 reward 186.0 MA(100) 205.56 eps 0.010\n",
      "Ep 4690 reward 235.0 MA(100) 207.07 eps 0.010\n",
      "Ep 4700 reward 164.0 MA(100) 206.95 eps 0.010\n",
      "q_table stats: min -1.096, mean 41.138, max 99.783\n",
      "Ep 4710 reward 172.0 MA(100) 202.46 eps 0.010\n",
      "Ep 4720 reward 421.0 MA(100) 198.95 eps 0.010\n",
      "Ep 4730 reward 195.0 MA(100) 198.99 eps 0.010\n",
      "Ep 4740 reward 177.0 MA(100) 195.28 eps 0.010\n",
      "Ep 4750 reward 140.0 MA(100) 198.49 eps 0.010\n",
      "Ep 4760 reward 181.0 MA(100) 197.40 eps 0.010\n",
      "Ep 4770 reward 134.0 MA(100) 198.62 eps 0.010\n",
      "Ep 4780 reward 213.0 MA(100) 198.20 eps 0.010\n",
      "Ep 4790 reward 224.0 MA(100) 195.65 eps 0.010\n",
      "Ep 4800 reward 218.0 MA(100) 193.32 eps 0.010\n",
      "q_table stats: min -1.121, mean 41.175, max 99.698\n",
      "Ep 4810 reward 134.0 MA(100) 191.61 eps 0.010\n",
      "Ep 4820 reward 166.0 MA(100) 193.69 eps 0.010\n",
      "Ep 4830 reward 246.0 MA(100) 196.94 eps 0.010\n",
      "Ep 4840 reward 178.0 MA(100) 204.12 eps 0.010\n",
      "Ep 4850 reward 233.0 MA(100) 201.33 eps 0.010\n",
      "Ep 4860 reward 135.0 MA(100) 197.17 eps 0.010\n",
      "Ep 4870 reward 242.0 MA(100) 199.05 eps 0.010\n",
      "Ep 4880 reward 280.0 MA(100) 201.07 eps 0.010\n",
      "Ep 4890 reward 202.0 MA(100) 200.52 eps 0.010\n",
      "Ep 4900 reward 174.0 MA(100) 202.95 eps 0.010\n",
      "q_table stats: min -1.148, mean 41.243, max 99.845\n",
      "Ep 4910 reward 125.0 MA(100) 203.90 eps 0.010\n",
      "Ep 4920 reward 121.0 MA(100) 201.38 eps 0.010\n",
      "Ep 4930 reward 253.0 MA(100) 202.19 eps 0.010\n",
      "Ep 4940 reward 368.0 MA(100) 198.00 eps 0.010\n",
      "Ep 4950 reward 264.0 MA(100) 204.92 eps 0.010\n",
      "Ep 4960 reward 276.0 MA(100) 205.06 eps 0.010\n",
      "Ep 4970 reward 194.0 MA(100) 206.12 eps 0.010\n",
      "Ep 4980 reward 349.0 MA(100) 205.99 eps 0.010\n",
      "Ep 4990 reward 161.0 MA(100) 208.39 eps 0.010\n",
      "Ep 5000 reward 166.0 MA(100) 205.29 eps 0.010\n",
      "q_table stats: min -1.174, mean 41.312, max 99.919\n",
      "Ep 5010 reward 194.0 MA(100) 204.64 eps 0.010\n",
      "Ep 5020 reward 171.0 MA(100) 210.34 eps 0.010\n",
      "Ep 5030 reward 221.0 MA(100) 206.11 eps 0.010\n",
      "Ep 5040 reward 230.0 MA(100) 207.28 eps 0.010\n",
      "Ep 5050 reward 217.0 MA(100) 206.14 eps 0.010\n",
      "Ep 5060 reward 186.0 MA(100) 207.41 eps 0.010\n",
      "Ep 5070 reward 214.0 MA(100) 204.55 eps 0.010\n",
      "Ep 5080 reward 277.0 MA(100) 201.06 eps 0.010\n",
      "Ep 5090 reward 279.0 MA(100) 204.09 eps 0.010\n",
      "Ep 5100 reward 342.0 MA(100) 205.83 eps 0.010\n",
      "q_table stats: min -1.201, mean 41.377, max 99.995\n",
      "Ep 5110 reward 217.0 MA(100) 210.34 eps 0.010\n",
      "Ep 5120 reward 122.0 MA(100) 210.19 eps 0.010\n",
      "Ep 5130 reward 165.0 MA(100) 209.01 eps 0.010\n",
      "Ep 5140 reward 480.0 MA(100) 209.60 eps 0.010\n",
      "Ep 5150 reward 202.0 MA(100) 210.16 eps 0.010\n",
      "Ep 5160 reward 179.0 MA(100) 216.74 eps 0.010\n",
      "Ep 5170 reward 182.0 MA(100) 223.34 eps 0.010\n",
      "Ep 5180 reward 181.0 MA(100) 228.94 eps 0.010\n",
      "Ep 5190 reward 470.0 MA(100) 227.18 eps 0.010\n",
      "Ep 5200 reward 138.0 MA(100) 230.31 eps 0.010\n",
      "q_table stats: min -1.241, mean 41.419, max 100.029\n",
      "Ep 5210 reward 231.0 MA(100) 225.46 eps 0.010\n",
      "Ep 5220 reward 149.0 MA(100) 223.01 eps 0.010\n",
      "Ep 5230 reward 140.0 MA(100) 236.70 eps 0.010\n",
      "Ep 5240 reward 171.0 MA(100) 236.19 eps 0.010\n",
      "Ep 5250 reward 194.0 MA(100) 232.70 eps 0.010\n",
      "Ep 5260 reward 134.0 MA(100) 226.62 eps 0.010\n",
      "Ep 5270 reward 172.0 MA(100) 220.26 eps 0.010\n",
      "Ep 5280 reward 173.0 MA(100) 215.83 eps 0.010\n",
      "Ep 5290 reward 480.0 MA(100) 218.65 eps 0.010\n",
      "Ep 5300 reward 350.0 MA(100) 229.22 eps 0.010\n",
      "q_table stats: min -1.277, mean 41.476, max 99.902\n",
      "Ep 5310 reward 480.0 MA(100) 258.00 eps 0.010\n",
      "Ep 5320 reward 480.0 MA(100) 285.04 eps 0.010\n",
      "Ep 5330 reward 191.0 MA(100) 283.77 eps 0.010\n",
      "Ep 5340 reward 480.0 MA(100) 285.72 eps 0.010\n",
      "Ep 5350 reward 480.0 MA(100) 302.44 eps 0.010\n",
      "Ep 5360 reward 480.0 MA(100) 328.01 eps 0.010\n",
      "Ep 5370 reward 480.0 MA(100) 349.35 eps 0.010\n",
      "Ep 5380 reward 480.0 MA(100) 377.98 eps 0.010\n",
      "Ep 5390 reward 480.0 MA(100) 400.77 eps 0.010\n",
      "Ep 5400 reward 480.0 MA(100) 413.82 eps 0.010\n",
      "q_table stats: min -1.333, mean 41.558, max 100.417\n",
      "Ep 5410 reward 480.0 MA(100) 415.48 eps 0.010\n",
      "Ep 5420 reward 480.0 MA(100) 415.48 eps 0.010\n",
      "Ep 5430 reward 480.0 MA(100) 433.28 eps 0.010\n",
      "Ep 5440 reward 480.0 MA(100) 456.21 eps 0.010\n",
      "Ep 5450 reward 480.0 MA(100) 467.54 eps 0.010\n",
      "Ep 5460 reward 480.0 MA(100) 470.55 eps 0.010\n",
      "Solved at episode 5466 (moving avg 477.47)\n"
     ]
    }
   ],
   "source": [
    "trained_agent = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef406a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(fql_agent, num_episodes=100, render=False, seed=None, max_steps=None, verbose=True):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    env = gym.make(config.ENV_NAME)\n",
    "    max_steps = max_steps or getattr(config, \"MAX_STEPS_PER_EPISODE\", 1000)\n",
    "\n",
    "    prev_eps = getattr(fql_agent, \"epsilon\", None)\n",
    "    if prev_eps is not None:\n",
    "        fql_agent.epsilon = 0.0\n",
    "\n",
    "    episode_rewards = []\n",
    "    try:\n",
    "        for ep in range(1, num_episodes + 1):\n",
    "            if seed is not None:\n",
    "                obs, _ = env.reset(seed=seed + ep)\n",
    "            else:\n",
    "                obs, _ = env.reset()\n",
    "\n",
    "            total_reward = 0.0\n",
    "            terminated = truncated = False\n",
    "            steps = 0\n",
    "            cart_pos, cart_vel, pole_angle, pole_ang_vel = obs\n",
    "            action = fql_agent.get_initial_action([float(pole_angle), float(pole_ang_vel)])\n",
    "\n",
    "            while not (terminated or truncated) and steps < max_steps:\n",
    "                obs, reward, terminated, truncated, _ = env.step(int(action))\n",
    "                total_reward += reward\n",
    "                steps += 1\n",
    "\n",
    "                if terminated or truncated:\n",
    "                    break\n",
    "\n",
    "                _, _, pole_angle, pole_ang_vel = obs\n",
    "                action = fql_agent.get_action([float(pole_angle), float(pole_ang_vel)])\n",
    "\n",
    "            episode_rewards.append(total_reward)\n",
    "\n",
    "            if verbose and (ep == 1 or ep % 10 == 0 or ep == num_episodes):\n",
    "                recent_ma = float(np.mean(episode_rewards[-100:]))\n",
    "                print(f\"[Test] Ep {ep}/{num_episodes} reward {total_reward:.1f} recent_MA({min(100,len(episode_rewards))}) {recent_ma:.2f}\")\n",
    "\n",
    "    finally:\n",
    "        if prev_eps is not None:\n",
    "            fql_agent.epsilon = prev_eps\n",
    "        env.close()\n",
    "\n",
    "    stats = {\n",
    "        \"mean\": float(np.mean(episode_rewards)),\n",
    "        \"std\": float(np.std(episode_rewards)),\n",
    "        \"min\": float(np.min(episode_rewards)),\n",
    "        \"max\": float(np.max(episode_rewards)),\n",
    "        \"median\": float(np.median(episode_rewards)),\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"=== Evaluation summary ===\")\n",
    "        print(f\"episodes: {len(episode_rewards)}  mean: {stats['mean']:.2f}  std: {stats['std']:.2f}  min: {stats['min']:.1f}  max: {stats['max']:.1f}\")\n",
    "\n",
    "    return episode_rewards, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b50bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Ep 1/50 reward 500.0 recent_MA(1) 500.00\n",
      "[Test] Ep 10/50 reward 500.0 recent_MA(10) 500.00\n",
      "[Test] Ep 20/50 reward 500.0 recent_MA(20) 500.00\n",
      "[Test] Ep 30/50 reward 500.0 recent_MA(30) 500.00\n",
      "[Test] Ep 40/50 reward 500.0 recent_MA(40) 500.00\n",
      "[Test] Ep 50/50 reward 500.0 recent_MA(50) 500.00\n",
      "=== Evaluation summary ===\n",
      "episodes: 50  mean: 500.00  std: 0.00  min: 500.0  max: 500.0\n"
     ]
    }
   ],
   "source": [
    "test_rewards, test_stats = test(trained_agent[0], num_episodes=50, render=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3149aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"q_table_best_ep{5700}.npy\", trained_agent[0].q_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
